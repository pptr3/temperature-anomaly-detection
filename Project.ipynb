{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "#from pyemma import msm # not available on Kaggle Kernel\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6373392b08e4b58b33041d15203ede0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_name = 'data/ambient_temperature_system_failure.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "def plot_series(df):\n",
    "    # change the type of timestamp column for plotting\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    # change fahrenheit to °C (temperature mean= 71 -> fahrenheit)\n",
    "    df['value'] = (df['value'] - 32) * 5/9\n",
    "    # plot the data\n",
    "    df.plot(x='timestamp', y='value')\n",
    "    \n",
    "plot_series(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hours and if it's night or day (7:00-22:00)\n",
    "df['hours'] = df['timestamp'].dt.hour\n",
    "df['daylight'] = ((df['hours'] >= 7) & (df['hours'] <= 22)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DayOfTheWeek'] = df['timestamp'].dt.dayofweek\n",
    "df['WeekDay'] = (df['DayOfTheWeek'] < 5).astype(int)\n",
    "# An estimation of anomly population of the dataset (necessary for several algorithm)\n",
    "outliers_fraction = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time with int to plot easily\n",
    "df['time_epoch'] = (df['timestamp'].astype(np.int64)/100000000000).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of 4 distinct categories that seem useful (week end/day week & night/day)\n",
    "df['categories'] = df['WeekDay']*2 + df['daylight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Cluster only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take useful feature and standardize them\n",
    "data = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "# reduce to 2 importants features\n",
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(data)\n",
    "# standardize these 2 new features\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow method kmens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c548d316b62541fb8156d160660e86e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate with different number of centroids to see the loss plot (elbow method)\n",
    "n_cluster = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3721\n",
       "0    1522\n",
       "2    1428\n",
       "3     596\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I choose 4 centroids arbitrarily and add these data to the central dataframe\n",
    "df['cluster'] = kmeans[3].predict(data)\n",
    "df['principal_feature1'] = data[0]\n",
    "df['principal_feature2'] = data[1]\n",
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808b3f251888428d9f62d91e4e23193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the different clusters with the 2 main principal components\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'red', 1:'blue', 2:'green', 3:'pink', 4:'black', 5:'orange'}\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"cluster\"].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return Series of distance between each point and his distance with the closest centroid\n",
    "def getDistanceByPoint(data, model):\n",
    "    distance = []\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.append(np.linalg.norm(Xa-Xb))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between each point and its nearest centroid. The biggest distances are considered as anomaly\n",
    "distance = getDistanceByPoint(data, kmeans[4])\n",
    "number_of_outliers = int(outliers_fraction*len(distance))\n",
    "threshold = heapq.nlargest(number_of_outliers, distance)[-1]\n",
    "# anomaly21 contain the anomaly result of method 2.1 Cluster (0:normal, 1:anomaly) \n",
    "df['anomaly21'] = (distance >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543bb640b364e6cbd00e286d444950c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualisation of anomaly with cluster view\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'blue', 1:'red'}\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"anomaly21\"].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ab162511ea4d4d9df4bd4944df9f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualisation of anomaly throughout time (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly21'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
